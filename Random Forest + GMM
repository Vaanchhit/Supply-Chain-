# Install required packages
!pip install pandas scikit-learn matplotlib seaborn openpyxl

# Step 1: Upload Excel File (Dynamic)
from google.colab import files
import pandas as pd
import io

# Upload and read Excel
uploaded = files.upload()
for filename in uploaded.keys():
    file_path = filename

# Load Excel file
xls = pd.ExcelFile(file_path)
print("Available sheets:", xls.sheet_names)

# Load the first sheet by default
df = pd.read_excel(xls, sheet_name=xls.sheet_names[0])

# Preview
print("Columns in uploaded file:", df.columns.tolist())
df.head()

# Step 2: Define Features & Labels Dynamically
# Customize based on your file
non_feature_cols = ['WD_ID', 'Name', 'City', 'Date']  # Add/remove as needed
label_col = 'Shut_Flag'  # Must be 0 or 1 for active/shut

# Dynamically pick numeric features
feature_cols = [col for col in df.columns 
                if col not in non_feature_cols + [label_col] 
                and pd.api.types.is_numeric_dtype(df[col])]

features = df[feature_cols]
labels = df[label_col]

# Step 3: Train Random Forest for Risk Scoring
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler

# Normalize features
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(features)

# Train Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_scaled, labels)

# Feature importances
feature_weights = rf.feature_importances_
feature_df = pd.DataFrame({
    'Feature': feature_cols,
    'Importance': feature_weights
}).sort_values(by='Importance', ascending=False)

# Predict risk probabilities
df['Risk_Score'] = rf.predict_proba(X_scaled)[:, 1]

# Show top predictors
feature_df

# Step 4: Apply Dynamic Feature Weighting
weighted_features = X_scaled * feature_weights
X_weighted_df = pd.DataFrame(weighted_features, columns=feature_cols)

# Optionally include Risk Score as a feature for clustering
X_weighted_df['Risk_Score'] = df['Risk_Score']

# Step 5: Cluster Using GMM
from sklearn.mixture import GaussianMixture

# GMM with 3 clusters (tweak as needed)
gmm = GaussianMixture(n_components=3, random_state=42)
df['Cluster'] = gmm.fit_predict(X_weighted_df)

# Add cluster probabilities if needed
# df[['Cluster_0', 'Cluster_1', 'Cluster_2']] = gmm.predict_proba(X_weighted_df)

# Step 6: Visualize Cluster Profiles
import seaborn as sns
import matplotlib.pyplot as plt

# Show average feature values by cluster
cluster_summary = df.groupby('Cluster')[feature_cols + ['Risk_Score']].mean()

# Plot heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(cluster_summary, annot=True, cmap='YlGnBu', fmt=".2f")
plt.title("Cluster Behavior Summary")
plt.show()

# Step 7: Export the clustered results
df.to_csv('clustered_wd_output.csv', index=False)
print("Clustered data exported successfully.")
